# ğŸš€ AWS Lambda S3 to MinIO Replication

## ğŸ“Œ Project Overview
This project implements an AWS Lambda function to replicate objects from an AWS S3 bucket to a MinIO storage system. It automatically synchronizes file uploads and deletions, ensuring data consistency across cloud storage solutions.

---

## ğŸ¯ Use Cases
- âœ… Automatic replication of new objects from AWS S3 to MinIO.
- ğŸ› ï¸ Synchronization of deletions across storage platforms.
- ğŸ”„ Ensuring data availability in multiple storage backends.
- ğŸ” Secure transfer of files with IAM roles and access keys.

---

## ğŸš€ Advantages
- ğŸ—ï¸ **Scalability:** Supports high-volume data replication.
- ğŸ”„ **Automated Synchronization:** No manual intervention required.
- âš¡ **Fast & Efficient:** Uses AWS Lambda for real-time event-driven replication.
- ğŸ”’ **Secure:** IAM policies ensure data protection.
- ğŸ› ï¸ **Easy Integration:** Works with AWS S3 and MinIO seamlessly.

---

## ğŸ—ï¸ Architecture Setup
### ğŸ“ Steps to Deploy
1ï¸âƒ£ **Create a Lambda Function:**
   - Use AWS Lambda with runtime **Python 3.10**.

2ï¸âƒ£ **Setup IAM Role:**
   - Attach an IAM role with **S3 Full Access** permissions.

3ï¸âƒ£ **Inline Policy for S3 Permissions:**
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::s3_name/*",
                "arn:aws:s3:::s3_name"
            ]
        }
    ]
}
```

4ï¸âƒ£ **Deploy Lambda Function:**
   - Install dependencies & package the function.

```sh
mkdir -p lambda_package
vim lambda_function.py  # Paste the function code
pip install minio -t lambda_package/
cd lambda_package
zip -r ../lambda_function.zip .
cd ..
zip -g lambda_function.zip lambda_function.py
```

5ï¸âƒ£ **Upload & Deploy Lambda Function:**
   - Go to AWS Lambda dashboard, upload `lambda_function.zip`, and deploy.

6ï¸âƒ£ **Configure S3 Event Notification:**
   - **Go to S3** â†’ **Bucket** â†’ **Properties** â†’ **Create Event Notification**
   - Choose **Object Created** & **Object Removed**
   - Select destination as **Lambda Function** and attach your function.

---

## ğŸ“œ Lambda Function Code
```python
import json
import boto3
import os
from minio import Minio
from minio.error import S3Error

# AWS S3 Client ğŸ¯
s3_client = boto3.client('s3')

# MinIO Client Configuration âš™ï¸
MINIO_ENDPOINT = "objectstore.e2enetworks.net"  # Remove "https://"
MINIO_ACCESS_KEY = "access key"
MINIO_SECRET_KEY = "secret key"
MINIO_BUCKET = "eos name"

minio_client = Minio(
   MINIO_ENDPOINT,
   access_key=MINIO_ACCESS_KEY,
   secret_key=MINIO_SECRET_KEY,
   secure=True  # Change to False if using HTTP
)

# Lambda Handler ğŸ—ï¸
def lambda_handler(event, context):
   try:
       for record in event['Records']:
           event_name = record['eventName']
           s3_bucket = record['s3']['bucket']['name']
           s3_object_key = record['s3']['object']['key']

           if event_name.startswith('ObjectCreated'):
               # Handle object creation: Copy the object to MinIO ğŸš€
               temp_file = f"/tmp/{s3_object_key.split('/')[-1]}"
               s3_client.download_file(s3_bucket, s3_object_key, temp_file)
               minio_client.fput_object(MINIO_BUCKET, s3_object_key, temp_file)
               print(f"âœ… Successfully replicated {s3_object_key} to MinIO")

           elif event_name.startswith('ObjectRemoved'):
               # Handle object deletion: Delete the object from MinIO âŒ
               minio_client.remove_object(MINIO_BUCKET, s3_object_key)
               print(f"ğŸ—‘ï¸ Successfully deleted {s3_object_key} from MinIO")

   except Exception as e:
       print(f"âš ï¸ Error: {e}")
       return {
           'statusCode': 500,
           'body': json.dumps('âŒ Replication Failed')
       }

   return {
       'statusCode': 200,
       'body': json.dumps('âœ… Replication Successful')
   }
```

---

## ğŸ“Œ Sample Test Event
To test the function manually, use this sample event:
```json
{
 "Records": [
   {
     "eventSource": "aws:s3",
     "eventName": "ObjectCreated:Put",
     "s3": {
       "bucket": {
         "name": "dr-k8s-velero"
       },
       "object": {
         "key": "python.pdf"
       }
     }
   }
 ]
}
```

---

## ğŸ› ï¸ Tools Used
- â˜ï¸ **AWS S3** - Cloud storage service
- ğŸ—ï¸ **EOS** - Enterprise Object Store
- ğŸ **Python3** - Programming language
- ğŸ”§ **MinIO Library** - For object storage operations

---

## ğŸ”¥ My Contribution
âœ… **Designed & implemented** the entire architecture
âœ… **Configured IAM roles** and security permissions
âœ… **Set up AWS Lambda function** and S3 event triggers
âœ… **Tested & deployed** the function for real-time synchronization

---

## ğŸ“¢ Conclusion
This AWS Lambda function automates the replication of files from AWS S3 to MinIO, ensuring seamless synchronization and high availability. ğŸš€ If you find this helpful, feel free to â­ the project and contribute! Happy coding! ğŸ˜ƒ
